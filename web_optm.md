# 乡村特色产业网站结构优化
## 网站现在存在的 3 点问题
- 网站结构非常混乱，目前有：一个前端、两个后台（spring boot后台和 python 后台）、两个数据库、一个前后端不分离的大模型网页。**怎么规范模块间结构？**
- 网站要求集成大模型，但是成本太大了，尤其是在需要长期部署的情况下。**怎么压缩成本？**
- 刘校长提到的需求- - - 把农业标准大模型拓展成一个可以适应多种任务的“产前-产中-产后”大模型。原先计划的解决方案是“智能体”，**怎么落实？**
## 当前结构
## 优化后结构
1. 拆开 [gradio 库](https://www.gradio.app/)，重写大模型部分前后端
- 这个库的优点就是，几行代码就可以构建一个大模型的聊天窗口，非常方便，避免了传统的前后端两边的搭建
- 但是这个库不太适合用于构建非常非常复杂的项目
- 这个库比较小众，框架写法有点反直觉，学习成本大。如果不改，以后研一同学想要维护、修改大模型部分代码，还得学这个库
2. 微服务
- SQ 服务质量评价
- 大模型后台
- 微信外挂【？这个是否需要保留？】
## 适应 16G 内存的模型优化
### 关于[chatGLM3](https://github.com/zai-org/ChatGLM3)
1. 发布时间 2023 年，模型大小 6B （60 亿参数）
2. CPU上部署需要32G，可采用量化，但是pytorch本身会占用较大内存，还有中间结果的存储，导致量化完毕该模型也容易处在内存溢出的边缘。
- 高并发问题，只要有两个用户同时访问大模型，后台就会因为显存溢出而崩溃，然后后台会尝试自动重启，这段时间里网站不可用

![](https://pic-gino-prod.oss-cn-qingdao.aliyuncs.com/zhangli2025/20251020155933099-paste.png)
### 近些年大模型发展迅猛，轻量化是发展方向之一
2. chatGLM 模型相对较老了，自从 deepseek 火出圈之后，大模型在这段时间发展迅猛，很多 25 年的轻量级模型比 2 年前的大参数模型还好
3. 目前开源的轻量级模型越来越多，响应快、不挑设备、不会让网站变得很笨重。
4. 候选轻量级大模型：**理想大小是 2到4B**，可以先到 huggingface 使用一下看效果
- [百度文心一言: 0.3B](https://blog.csdn.net/gitblog_00728/article/details/152298565)
  - 也太小了，担心性能
  - 基于百度飞桨平台而不是 pytorch，与其他模块融合困难
- [腾讯混元0.5B/1.8B/4B/7B](https://blog.csdn.net/gitblog_00049/article/details/153553008)
- 千问
- [Gemma2B](https://cloud.tencent.com/developer/article/2391164)
- [MiniCPM4-0.5B](https://qbitai.com/2025/06/292581.html)

以下图片来自该模型的 github 介绍:[链接](https://github.com/OpenBMB/MiniCPM/blob/main/README.md)

这个模型的 4B 版本就宣称比 9B 的 GLM4 性能差不多，而我们目前使用的大模型是 6B 的 GLM3 。如果把**基座模型**换成这个 MiniCPM 也行可以在保证性能不变甚至提升的前提下，减少了 20 亿的参数量，减轻了设备压力。

还可以进一步尝试一下 MiniCPM 的 0.5B 版本，如果效果还不错的话，那只要普通的云服务器就可以运行了，毫无压力，完全摆脱了大模型部署困境。

![](https://pic-gino-prod.oss-cn-qingdao.aliyuncs.com/zhangli2025/20251023140318081-paste.png)

## 针对刘校长的一系列需求
最简单且实用的解决方法，暂时把智能体作为未来展望，先完成农标通的介入并保证性能
- 逻辑路由，效果不会也可调用大模型自身进行意图识别
- 提示词工程
  - prompty（新建文件夹，编写各种任务下的提示词、默认提示词、异常提示词）
  - STAR 编写法
  - jinja2 动态模板
  - markdown
    - 因为大模型是采用 mardwon 数据训练的，它的属于也是 markdown 格式，因此这种类型的提示词更利于理解）
- RAG 召回有效信息
## RAG 优化
使用 ElasticSearch ,把向量数据库和关键词数据库合二为一
