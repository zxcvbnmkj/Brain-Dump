# 乡村特色产业网站结构优化
## 当前结构
## 优化后结构
1. 拆开 [gradio 库](https://www.gradio.app/)，重写大模型部分前后端
- 这个库的优点就是，几行代码就可以构建一个大模型的聊天窗口，非常方便，避免了传统的前后端两边的搭建
- 但是这个库不太适合用于构建非常非常复杂的项目
- 这个库比较小众，框架写法有点反直觉，学习成本大。如果不改，以后研一同学想要维护、修改大模型部分代码，还得学这个库
2. 微服务
- SQ 服务质量评价
- 大模型后台
- 微信外挂
## 适应 16G 内存的模型优化
### 关于[chatGLM3](https://github.com/zai-org/ChatGLM3)
1. 发布时间 2023 年，模型大小 6B （60 亿参数）
2. CPU上部署需要32G，可采用量化，但是pytorch本身会占用较大内存，还有中间结果的存储，导致量化完毕该模型也容易处在内存溢出的边缘

![](https://pic-gino-prod.oss-cn-qingdao.aliyuncs.com/zhangli2025/20251020155933099-paste.png)
### 近些年大模型发展迅猛，轻量化是发展方向之一
1. chatGLM 这个基座模型太大了，考虑到乡村特色产业网站以后还需要长期部署，如果集成现在的大模型进去，这个费用很难承担。
2. chatGLM 模型相对较老了，自从 deepseek 火出圈之后，大模型在这段时间发展迅猛，很多 25 年的轻量级模型比 2 年前的大参数模型还好
3. 目前开源的轻量级模型越来越多，响应快、不挑设备、不会让网站变得很笨重。
4. 候选轻量级大模型：**理想大小是 2到4B**，可以先到 huggingface 使用一下看效果
- [百度文心一言: 0.3B](https://blog.csdn.net/gitblog_00728/article/details/152298565)
  - 也太小了，担心性能
  - 基于百度飞桨平台而不是 pytorch，与其他模块融合困难
- [腾讯混元0.5B/1.8B/4B/7B](https://blog.csdn.net/gitblog_00049/article/details/153553008)
- 千问
- [Gemma2B](https://cloud.tencent.com/developer/article/2391164)
- [MiniCPM4-0.5B](https://qbitai.com/2025/06/292581.html)
## 针对刘校长的一系列需求
最简单且实用的解决方法，暂时把智能体作为未来展望，先完成农标通的介入并保证性能
- 逻辑路由，效果不会也可调用大模型自身进行意图识别
- 提示词工程
  - prompty（新建文件夹，编写各种任务下的提示词、默认提示词、异常提示词）
  - STAR 编写法
  - jinja2 动态模板
  - markdown
    - 因为大模型是采用 mardwon 数据训练的，它的属于也是 markdown 格式，因此这种类型的提示词更利于理解）
- RAG 召回有效信息
## RAG 优化
使用 ElasticSearch ,把向量数据库和关键词数据库合二为一
