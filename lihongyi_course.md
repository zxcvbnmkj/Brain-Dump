# 《生成式人工智能导论》观后感

## 提示词
- 把大模型想象成一个线上的新人助理
![](https://pic-gino-prod.oss-cn-qingdao.aliyuncs.com/zhangli2025/20251009022844446-paste.png)

### 可能提高模型效果的提示词设计方法
- CoT。对于复杂任务，提示词里可以将任务解法拆解成小的步骤，引导大模型思考。（简单任务应该没有必要）
- 强化学习 + 自动化测试 。尝试不同的提示词，筛选出较好的。得到的好提示词居然是人类不理解的乱七八糟的提示词，比如：ways ways ways ....
- 提供示例（ In-context Learning 技术）
- RAG

有趣现象（来源于一些论文对奇奇怪怪都市传说的测试，仅对部分模型有效）
- 情绪勒索似乎可以提升大模型输出内容的正确性，如提示词中强调 “这件事对我非常重要”
- 让大模型解释一下自己的回答，有助于提升回答准确率
- 对大模型有礼貌并不会得到性能提升
- 不要对大模型说反话，避免输入：不要干什么、禁止干什么，直接输入需要做什么
- 口头威胁或假装奖励居然能提升大模型效果
- 尝试问大模型，我需要解决一个什么问题，有没有什么准确率比较好的提示词
- 让大模型深呼吸一下，它的能力变得更强了😂
-
cot完成后，多加一个步骤，让大模型检查自己的输出，判断是否有误

参数冻结，温度为9，top k为1的情况下，模型输入的结果还是不同

tot。生成-反省-选择

PoT（program）   类似于智能体，调用外部工具。比如在解复杂数学问题，会先生成代码，然后调用外部工具执行代码。（生成特殊符号，用来表示需要调用的工具编号）

类似于多智能体。模型合作（上游模型选择下游模型、反省、讨论）
通过判断是否达成共识来决定是否停止讨论。可以设置一个裁判模型判断
![](https://pic-gino-prod.oss-cn-qingdao.aliyuncs.com/zhangli2025/20251009092100224-paste.png)




预训练阶段：所选择的语料质量非常重要，若在混乱的语料上预训练，模型参数规模再大性能也难以提升


模型可接受性
- `local explain`
- `global explain`
