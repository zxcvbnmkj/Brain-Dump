# 《生成式人工智能导论》观后感
## 第一讲：生成式 AI 是什么？
### 课程要点总结
如何做到不断生成？
- 文字接龙模式，不断把本次生成的一个字追加到输入序列末尾，这种方法称为**自回归生成（Autoregressive Generation）**
- **生成问题的本质是分类问题**，类别个数 = `vocab.txt` 中的 token 个数，模型输出每个 token 的概率
- 理论上，对于图片生成 AI，可以使用像素接龙，openAI 曾经有尝试过这种方法，但这种方法有缺陷，现在已经不采用，已被扩散模型代替
### 扩展
- Transformer 采用**编码器-解码器**结构，几乎所有的大模型都基于 Transformer ，但是目前主流的大模型（GPT、LLaMA 等）结构却是**仅解码器（Dncoder-only）** 并使用**单向注意力**（只关注前文词语），因为这样更加高效。
- BERT 以及它的变体（如 RoBERTa）则采用**仅编码器（Encoder-only）** 结构并使用**双向注意力**。因为 BERT 的核心能力是**语义理解**，它一般用于分类任务。
## 第三/四/五讲：山不过来，我就过去
### 课程要点总结
- 把大模型想象成一个刚来的实习生，它具备处理问题的基本能力，只是不知道问题背景和处理流程，因此提示词工程可以解决大模型的大部分问题。
#### 可能提高模型效果的提示词设计方法
- **强化学习 + 自动化测试** : 尝试不同的提示词，筛选出较好的，提示词由另一个模型生成。但是得到的可能是无厘头提示词，比如某任务得到的得到的最佳提示词居然是`ways ways ways ....`
- **In-context Learning 技术**：即提供一个示例
- **RAG**
- **思维链 CoT** : 对于复杂任务，提示词可以将任务拆解成小的步骤，引导大模型思考。（简单任务应该没有必要）
- **程序思维 PoT（Program of Thoughts）**: 调用外部工具。比如，在解复杂数学问题，会先生成代码，然后调用外部工具执行代码。（生成特殊符号，用来表示需要调用的工具编号）
- **思维树 ToT**：生成-反省-选择

![](https://pic-gino-prod.oss-cn-qingdao.aliyuncs.com/zhangli2025/20251009105731860-paste.png)

- **多模型合作** ：类似于多智能体系统。比如：上游模型选择下游模型、反省、讨论

通过判断是否达成共识来决定是否停止讨论。可以设置一个裁判模型判断

![](https://pic-gino-prod.oss-cn-qingdao.aliyuncs.com/zhangli2025/20251009092100224-paste.png)
#### 关于提示词的有趣现象（来源于一些论文对奇奇怪怪都市传说的测试，仅对部分模型有效）
1. 应当遵循
- 不要对大模型说反话，避免输入：不要干什么、禁止干什么，直接输入需要做什么
- 对大模型有礼貌并不会得到性能提升
2. 技巧
- 情绪勒索似乎可以提升大模型输出内容的正确性，如提示词中强调 “这件事对我非常重要”
- 让大模型解释一下自己的回答，有助于提升回答准确率
- 口头威胁或假装奖励居然能提升大模型效果
- 尝试问大模型，我需要解决一个什么问题，有没有什么准确率比较好的提示词
- 让大模型深呼吸一下，它的能力变得更强了😂
- `CoT` 完成后，多加一个步骤，让大模型检查自己的输出，判断是否有误，可提升效果
### 扩展
#### 思维链
以xx为例介绍自己最熟悉的那种思维链
#### 曾经看到的，非常震惊的论文《如何使用大模型生成一篇专利》
- 如果是生成短篇小说，那倒不奇怪，只要拆分任务，大模型完全可以做到（比如，无忌哥的大模型写书计划）
- 我曾经遇到过大模型算数算错了，我把 word 表格形式的成绩单（不存在 ORC 识别错数字的情况）复制到大模型中，让它算一下平均分，但是它计算错了，多算了 0.1 分？？奇怪为什么
- 大模型给人的印象是更擅长文本内容的生成，但是数字不擅长（比如，知乎曾经的热搜，0.001和0.18谁打，难道是因为大模型把数字当做文本处理，没有考虑到小数点后位数的特殊性吗）
- 专利不同于普通短文，它具有下面这些特点，所以看到可以直接生成一篇专利，当时真的非常震惊
  - 存在大量公式
  - 格式有严格的要求
  - 逻辑要非常严谨
  - 一篇专利非常的长
#### 思维链是过时的技术吗？
- 当然一个技术很旧不代表它完全没用，就算是机器学习、LSTM 这种在特定任务中也有独特优势。我们这里只讨论这个技术现在是不是研究人员的第一选择，有没有出现它的上位替代品。
- 思维链，同时包括它的 N 种变体，已经被提出非常多年了。近几年，提到它一般会这样写：“传统大模型通常利用思维链xxx，但是它存在着xx的缺点，而xx技术凭借着xx克服这一问题”，把思维链作为旧事物去引出新技术
#### 思维链、workflow、提示词中的 action 部分间的关系
- 思维链是写明步骤，还是分治法去拆分成多个子任务呢
#### 思维链写法，举一个代码实例
## 第六讲：大模型修炼史：自我学习，累积实力
- 预训练阶段所选择的语料质量非常重要，若在混乱的语料上预训练，模型参数规模再大性能也难以提升


### 模型可解释性
- `local explain`
- `global explain`
### 疑问
在冻结模型参数并保证提示词一样的情况下，即使设置了 `temperature=0` 和 `top_k=1` ，理论上每一次运行所得输出应该是一样的，但实际上仍然可能出现不同的结果

用处：判断是否书面语，琪琪哥方案“大模型输出关键字符时的 TopN 概率”

原因可能是：
- 不确定性主要归咎于计算机处理浮点数时顺序不同会导致微小误差，而并行运算又放大了这些差异
- 批次不变性缺失，服务器一次处理多少请求，会影响最终输出

保证生成结果的一致性的好处：
- 有助于提升模型可接受性
- 对需保证可靠性的任务来说有重要意义
- 在强化学习中可以更严格的控制变量

目前有论文[[1]](https://arxiv.org/abs/2506.09501)对这一方面进行研究[[2]](https://it.sohu.com/a/933907971_211762)





## 智能体- - -一个非常熟悉的陌生人
- 我可能对智能体的理论定义非常熟悉，因为它一直是导师眼里的研究热点，只要申报项目就必扯智能体，导师也总结出了一套项目申报黄金范式：普通深度学习技术（大模型不擅长的，以此作为工具）-->大模型（强调它的不足）->智能体（调用工具）->多智能体系统 MAS（通信、共识）
### 智能体的理论定义
### 怎么实现，是通过低代码工具吗？

## 大模型应用的三种境界
现在豆包、deepseek 模型有网页版本、手机 APP，普通用户使用起来非常方便。既然如此，为什么我们还要在豆包等大模型的基础上去开发，意义是什么，用户干嘛不去用豆包要来用我们开发的东西？？？
1. 赋能、润物细无声，大模型支撑着某项功能，但是用户完全感觉不到，大模型被包裹在功能内部
- AI 面试系统，以及评分
2. 利用大模型跟已有系统互动，用户可以感觉到大模型的存在。可代替强
- cursor 以及其他 IDE 中集成的 AI 聊天框
- CSDN 现在在编写文章的时候，右侧也有一个 AI 聊天框
- 牛客智搜，融入牛客特色的 AI 聊天框
3. 我们的东西完全和豆包等模型撞车，没有特色，没有区分度。属于意义不明，纯粹跟风，走个形式
- 我学校官网的 deepseek。deepseek 火出圈的时候，学校就在自己的网站上部署了一个（也可能是调用 API ），然后学院大群通知所有同学，我们学校有自己的 deepseek 了，欢迎体验
- 我在学校负责的“农标通大模型 AgristdLLM”
  - 它有自己独特的定位，面向农户，用于回答种植、养殖方面的问题，助力农业标准化生产
  - 它被精心调整过，采用了 “Lora 微调 + RAG”，光是收集数据就花了非常久，这一步进行的非常艰难
  - 它被部署在年租过万的服务器上面，其中注明了公测版，但现实是除了托以外 0 个人来测
  - 即使为了它付出了非常多心血，但是根本无人问津。究其原因，我认为是它可以做到的，豆包等模型也可以，用户会偏向于使用自己熟悉的模型，根本没必要打开一个陌生且卡的网站，如果这个网站没有一些仅自己有的，非常有特色的东西的话
  - 由于现在的大模型日益强大，农户的一些基本问题，通用大模型完全可以解决，开发农标通的意义在哪里。即使农标通开发的那么艰难，又是微调又是知识库，但它的性能没有明显优于最近出现的通用大模型，用户的体验可能是，我们调的是 API ，感觉上面的行动白费了
  - 导师原计划是好好宣称一下，让学院公众号写一篇推文，说我们组有自己的大模型了，现在已经有 xx 名用户注册，每个月的访问量高达 xx。但是泡汤了，推广非常难，很多人都懒得去注册
  - 反思：不识庐山真面目，只缘身在此山中。项目进行时自以为是第一个研究大模型的组，充满了自信，更多的是在向别的组展示，我们现在在研究这个
### 关于 API 一些高校的态度
- 我在学校的时候从来没有用过 API，看到了 open AI key 就会跳过这个项目，如果一个模型不开放权重（比如豆包），就会忽略掉它去找别的
- 如果在组会上跟老师说，我们可以用 API 肯定会被批评，会被反问：那你的工作体现在哪里
- 估计是因为，高校拿到课题经费是用来研究的，而 API 被封装好了，是别人的东西，没有一点研究价值。而且这种费用不好报销
- **UltraFlow 是否可以适用于本地部署的大模型，是否需要把本地大模型包装为接口形式，并符合 OpenAI 的 API 规范**
## 模型轻量化的趋势 和 基座大模型怎么选择？
## 还有一线生机？怎么拯救“农标通”？
- 选用轻量化模型代替 6B 的比较老的 chatGLM，节约成本
- 把重点放在该网站中独有的功能上，比如标准 pdf、服务提供者信息等
- 参照上面那篇生成专利的论文，能不能尝试让农标通生成标准规范文件的初稿，提供给编撰标准的学校师生用。
- **专注小众赛道**，避免侧重点和大厂通用模型重合
- 标准文件生成是一个很难的任务，生成标准文件本身就需要参考其他非常多的标准化文件（它们内部存在相互引用），就算是豆包也很难做好，而我们网站中正好存储了大量的标准文件，这可能是农标通死灰复燃的机会
- Todo: 跑一下专利生成的论文代码，评估一下可行性
